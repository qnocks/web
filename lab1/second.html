<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Вторая страница</title>
</head>
<body>
    <div>
        <h1>Нейронные сети</h1>
		<div>
		  <ul>
		  	<li><a href="index.html">Главная страница</a></li>
		    <li><a href="second.html">Как это работает?</a></li>
		    <li><a href="sources.html">Источники информации</a></li>
		    <li><a href="#">Сценарий JavaScript</a></li>
		    <li><a href="#">Анкета</a></li>
		    <li><a href="#">Таблицы из базы данных</a></li>
		    <li><a href="#">Таблицы из xml</a></li>
		  </ul>
		</div>
    </div>
    <div>
        <h2>Как работают нейронные сети?</h2>
        <img src="https://hsto.org/r/w1560/files/8bf/88c/293/8bf88c293fc64a55bf09ea3e8c991ecb.png" alt="">
        <div>
            В данном примере изображена часть нейронной сети, где буквами I обозначены входные нейроны, буквой H — скрытый нейрон, а буквой w — веса.
            Из формулы видно, что входная информация — это сумма всех входных данных, умноженных на соответствующие им веса. Тогда дадим на вход 1 и 0.
            Пусть w1=0.4 и w2 = 0.7 Входные данные нейрона Н1 будут следующими: 1*0.4+0*0.7=0.4. Теперь когда у нас есть входные данные, мы можем
            получить выходные данные, подставив входное значение в функцию активации (подробнее о ней далее). Теперь, когда у нас есть выходные данные,
            мы передаем их дальше. И так, мы повторяем для всех слоев, пока не дойдем до выходного нейрона. Запустив такую сеть в первый раз мы увидим,
            что ответ далек от правильно, потому что сеть не натренирована. Чтобы улучшить результаты мы будем ее тренировать. Но прежде чем узнать как
            это делать, давайте введем несколько терминов и свойств нейронной сети.
        </div>
        <div>
            <p>Функция активации

            Функция активации — это способ нормализации входных данных (мы уже говорили об этом ранее). То есть, если на входе у вас будет большое число,
            пропустив его через функцию активации, вы получите выход в нужном вам диапазоне. Функций активации достаточно много поэтому мы рассмотрим самые
            основные: Линейная, Сигмоид (Логистическая) и Гиперболический тангенс. Главные их отличия — это диапазон значений.

            <p>Линейная функция</p>
            <img src="https://habrastorage.org/r/w1560/files/84d/a8a/f6b/84da8af6b86c4c48bcaafb5be1c53ff6.png" alt="">
            <p>Эта функция почти никогда не используется, за исключением случаев, когда нужно протестировать нейронную сеть или передать значение без преобразований.</p>

            <p>Сигмоид</p>
            <img src="https://habrastorage.org/r/w1560/files/150/8ef/062/1508ef06235444c3bc74a942812b4eb7.png" alt="">
            <p>Это самая распространенная функция активации, ее диапазон значений [0,1]. Именно на ней показано большинство примеров в сети, также ее иногда называют
            логистической функцией. Соответственно, если в вашем случае присутствуют отрицательные значения (например, акции могут идти не только вверх, но и вниз),
            то вам понадобиться функция которая захватывает и отрицательные значения.</p>

            <p>Гиперболический тангенс</p>
            <img src="https://habrastorage.org/r/w1560/files/c71/db2/a75/c71db2a756494e5298ed1d5b5f15cbc9.png" alt="">
            <p>Имеет смысл использовать гиперболический тангенс, только тогда, когда ваши значения могут быть и отрицательными, и положительными, так как диапазон
            функции [-1,1]. Использовать эту функцию только с положительными значениями нецелесообразно так как это значительно ухудшит результаты вашей нейросети.</p>

            <p>Тренировочный сет</p>
            <p>Тренировочный сет — это последовательность данных, которыми оперирует нейронная сеть. В нашем случае исключающего или (xor) у нас всего 4 разных
            исхода то есть у нас будет 4 тренировочных сета: 0xor0=0, 0xor1=1, 1xor0=1,1xor1=0.</p>

            <p>Итерация</p>
            <p>Это своеобразный счетчик, который увеличивается каждый раз, когда нейронная сеть проходит один тренировочный сет. Другими словами, это общее количество
            тренировочных сетов пройденных нейронной сетью.</p>

            <p>Эпоха</p>
            <p>При инициализации нейронной сети эта величина устанавливается в 0 и имеет потолок, задаваемый вручную. Чем больше эпоха, тем лучше натренирована сеть и
            соответственно, ее результат. Эпоха увеличивается каждый раз, когда мы проходим весь набор тренировочных сетов, в нашем случае, 4 сетов или 4 итераций.</p>
            <img src="https://habrastorage.org/r/w1560/files/d73/0a6/439/d730a643937f45ca997d73eec4fabddd.png" alt="">
            <p>Важно не путать итерацию с эпохой и понимать последовательность их инкремента. Сначала n
            раз увеличивается итерация, а потом уже эпоха и никак не наоборот. Другими словами, нельзя сначала тренировать нейросеть только на одном сете, потом на другом 
            и тд. Нужно тренировать каждый сет один раз за эпоху. Так, вы сможете избежать ошибок в вычислениях.</p>

            <p>Ошибка</p>
            <p>Ошибка — это процентная величина, отражающая расхождение между ожидаемым и полученным ответами. Ошибка формируется каждую эпоху и должна идти на спад.
            Если этого не происходит, значит, вы что-то делаете не так. Ошибку можно вычислить разными путями, но мы рассмотрим лишь три основных способа: Mean Squared Error (далее MSE),
            Root MSE и Arctan. Здесь нет какого-либо ограничения на использование, как в функции активации, и вы вольны выбрать любой метод, который будет приносить вам наилучший результат.
            Стоит лишь учитывать, что каждый метод считает ошибки по разному. У Arctan, ошибка, почти всегда, будет больше, так как он работает по принципу: чем больше разница, тем больше ошибка.
            У Root MSE будет наименьшая ошибка, поэтому, чаще всего, используют MSE, которая сохраняет баланс в вычислении ошибки.</p>

            <p>MSE</p>
            <img src="https://habrastorage.org/r/w1560/files/8b2/b5a/997/8b2b5a9974f841a0af487f671aae850b.png" alt="">
            <p>Root MSE</p>
            <img src="https://habrastorage.org/r/w1560/files/2dc/6e7/193/2dc6e7193baa47178ddd5ea8f33faa11.png" alt="">
            <p>Arctan</p>
            <img src="https://habrastorage.org/r/w1560/files/7df/1a8/e0f/7df1a8e0f36944af87d7452701c97624.png" alt="">

            <p>Принцип подсчета ошибки во всех случаях одинаков. За каждый сет, мы считаем ошибку, отняв от идеального ответа, полученный.
            Далее, либо возводим в квадрат, либо вычисляем квадратный тангенс из этой разности, после чего полученное число делим на количество сетов.</p>
        </div>
    </div>
    <div>
        <br>
		<br>
		Все права защищены 2022 &copy
    </div>
</body>
</html>